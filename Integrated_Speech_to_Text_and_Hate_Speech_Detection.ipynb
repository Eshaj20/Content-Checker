{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Essential imports from both notebooks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Integrated Speech-to-Text and Hate Speech Detection Notebook\n",
    "\n",
    "This notebook combines functionalities to:\n",
    "1. Convert audio input into text using a Speech-to-Text model.\n",
    "2. Analyze the transcribed text for hate speech using a text classification model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Wav2Vec2 model and tokenizer\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def speech_to_text(audio_path):\n",
    "    # Load audio file\n",
    "    audio_input, _ = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    # Tokenize and predict\n",
    "    input_values = tokenizer(audio_input, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    logits = model(input_values).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # Decode transcription\n",
    "    transcription = tokenizer.decode(predicted_ids[0])\n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load hate speech detection model (Hugging Face pipeline)\n",
    "def load_hate_speech_model():\n",
    "    print(\"Loading hate speech detection model...\")\n",
    "    model = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-offensive\")\n",
    "    return model\n",
    "\n",
    "# Analyze text for hate speech\n",
    "def analyze_text_for_hate_speech(model, text):\n",
    "    result = model(text)\n",
    "    print(f\"Analysis: {result}\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: HELLO MY NAME IS ESHA\n",
      "Loading hate speech detection model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058c8d13f1d349a48de56a89ccdb87e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58ffa83686c4dfa95ed789a005bc38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80f1a4578c944a8b608cdea973fd436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43c455a048d4409a61e01c4c2389533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c662c2944c41348b9b4a768b5660a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd29abaa570d4d978a4e465d61682133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis: [{'label': 'non-offensive', 'score': 0.8386955857276917}]\n",
      "Final Output: [{'label': 'non-offensive', 'score': 0.8386955857276917}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/cardiffnlp/twitter-roberta-base-offensive/35ebad0cb76d64c2ce454fc8514c69408ebf8cba6909f454aacbe28e07a0393d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1737556288&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzU1NjI4OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9jYXJkaWZmbmxwL3R3aXR0ZXItcm9iZXJ0YS1iYXNlLW9mZmVuc2l2ZS8zNWViYWQwY2I3NmQ2NGMyY2U0NTRmYzg1MTRjNjk0MDhlYmY4Y2JhNjkwOWY0NTRhYWNiZTI4ZTA3YTAzOTNkP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiJ9XX0_&Signature=tRNZJBfUwLJcxEeaUyKPJrmYz7MPQSBlVpQlsjjtVG660e6vBWUSYrVcylNJNcw9eyasCEWLkTrhq3y%7EpEuIwVPiVT48CrbLfmx6gRCUuC%7EZPoOZlxHI8pyMdcuIUjRAkGo-G0S04how1vqsyM-RY68%7ENSw87WHdRM3olnnFnJf8vUrgB14cjhkF-ZUvDfk8grkbFdNO9xoAwD08L5PLNRoZD3kYl2F-agrMrzVWxp2ENhtlZg9B6EQYV-ejutPzfywT6ecwFQN-YRgJgFiCzY90JPs3Q6i%7EmNFY-vzapUC8cjHArRy2iGoN8qgS%7ER6rFRzJrgtruPPUYNVlQ69JMQ__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37cdd370917444382484b22a67f39b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  74%|#######3  | 367M/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Main workflow to combine speech-to-text and hate speech detection\n",
    "def main(audio_path):\n",
    "    # Step 1: Speech-to-text transcription\n",
    "    transcription = speech_to_text(audio_path)\n",
    "    if transcription:\n",
    "        # Step 2: Load hate speech detection model\n",
    "        model = load_hate_speech_model()\n",
    "        \n",
    "        # Step 3: Analyze transcription for hate speech\n",
    "        result = analyze_text_for_hate_speech(model, transcription)\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No transcription available for analysis.\")\n",
    "        return None\n",
    "\n",
    "# Run the workflow (provide the path to an audio file)\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file_path = \"C:/Users/eshaa/Downloads/Myaudio.wav\"\n",
    "    output = main(audio_file_path)\n",
    "    print(f\"Final Output: {output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
